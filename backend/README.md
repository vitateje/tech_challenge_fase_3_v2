# quimicAI - Backend

API backend para a plataforma de aprendizado de quÃ­mica com IA.

## ğŸš€ Tecnologias

- **Node.js** - Runtime JavaScript
- **Express.js** - Framework web
- **MongoDB** - Banco de dados
- **LangChain** - Framework para LLM
- **Pinecone** - Vector database
- **Gemini/OpenAI/Ollama** - Provedores LLM

## ğŸ“ Estrutura

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.js              # Servidor Express
â”‚   â”œâ”€â”€ app.js                  # ConfiguraÃ§Ã£o do app
â”‚   â”œâ”€â”€ routes/                 # Rotas da API
â”‚   â”œâ”€â”€ controllers/            # Controladores
â”‚   â”œâ”€â”€ services/               # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ repositories/           # Camada de dados
â”‚   â”œâ”€â”€ models/                 # Modelos MongoDB
â”‚   â”œâ”€â”€ middleware/             # Middlewares
â”‚   â”œâ”€â”€ langchain/              # Framework LangChain
â”‚   â”œâ”€â”€ providers/              # Provedores LLM
â”‚   â””â”€â”€ config/                 # ConfiguraÃ§Ãµes
â”œâ”€â”€ scripts/                    # Scripts utilitÃ¡rios
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o
â”‚   â”œâ”€â”€ SETUP.md               # Guia de setup
â”‚   â”œâ”€â”€ API.md                 # DocumentaÃ§Ã£o da API
â”‚   â”œâ”€â”€ RAG_INGESTION.md       # Guia de ingestion
â”‚   â””â”€â”€ ARCHITECTURE.md        # Arquitetura do sistema
â””â”€â”€ package.json
```

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. PrÃ©-requisitos

- Node.js 18+
- MongoDB (local ou Atlas)
- Conta Pinecone (para vector store)
- API key do Gemini ou OpenAI (opcional)

### 2. Instalar DependÃªncias

```bash
npm install
```

### 3. Configurar VariÃ¡veis de Ambiente

Copie `.env.example` para `.env` e configure:

```bash
cp .env.example .env
```

### 4. ConfiguraÃ§Ã£o MÃ­nima (.env)

```bash
# Servidor
BACKEND_PORT=4000
NODE_ENV=development

# MongoDB
MONGODB_URI=mongodb://localhost:27017/quimicai

# CORS
CORS_ORIGIN=http://localhost:3000

# LLM Provider
LLM_PROVIDER=gemini
GEMINI_API_KEY=sua_chave_aqui

# Pinecone (Vector Store)
USE_PINECONE=true
PINECONE_API_KEY=sua_chave_pinecone
PINECONE_INDEX_NAME=quimicai
PINECONE_ENVIRONMENT=us-east-1

# Embeddings
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
OLLAMA_BASE_URL=http://localhost:11434
```

## ğŸš€ ExecuÃ§Ã£o

### Desenvolvimento

```bash
npm run dev
```

### ProduÃ§Ã£o

```bash
npm start
```

## ğŸ“¡ API Endpoints

Veja documentaÃ§Ã£o completa em [docs/API.md](docs/API.md)

### Principais Endpoints

- `POST /api/auth/login` - Login
- `POST /api/chat/send/:userId` - Enviar mensagem
- `GET /api/chat/conversations/:userId` - Listar conversas
- `GET /api/student-activities/user/:userId` - Atividades do aluno
- `GET /api/rag/info` - InformaÃ§Ãµes do RAG

## ğŸ§  Sistema de IA

### LLM Providers

- **Gemini** (padrÃ£o) - Gratuito, boa qualidade
- **OpenAI** - Pago, excelente qualidade
- **Ollama** - Local, gratuito

### Vector Store

- **Pinecone** - Vector database cloud para RAG

## ğŸ“š DocumentaÃ§Ã£o

- [Setup Completo](docs/SETUP.md)
- [DocumentaÃ§Ã£o da API](docs/API.md)
- [Arquitetura do Sistema](docs/ARCHITECTURE.md)
- [Guia de Ingestion RAG](docs/RAG_INGESTION.md)

## ğŸ”§ Scripts UtilitÃ¡rios

```bash
# Testar LLM
npm test

# Alternar provedor LLM
npm run switch-llm gemini
```

## ğŸš€ Deploy

### VariÃ¡veis de Ambiente para ProduÃ§Ã£o

```bash
NODE_ENV=production
BACKEND_PORT=4000
MONGODB_URI=mongodb+srv://...
PINECONE_API_KEY=...
GEMINI_API_KEY=...
CORS_ORIGIN=https://seu-frontend.com
```

### Docker

```bash
docker build -t quimicai-backend .
docker run -p 4000:4000 quimicai-backend
```

## ğŸ“ Notas Importantes

- **Vector Store**: O sistema usa **Pinecone** como vector store padrÃ£o
- **Ingestion**: O processo de ingestion de documentos Ã© feito em projeto separado (veja [RAG_INGESTION.md](docs/RAG_INGESTION.md))
- **Upload**: Upload de PDFs via API foi removido - use scripts de ingestion

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues e pull requests.
