# ğŸ“‹ PrÃ©-Processamento de Dados MÃ©dicos para Fine-Tuning

Este diretÃ³rio contÃ©m o pipeline completo de **prÃ©-processamento** de dados mÃ©dicos para fine-tuning de modelos LLM (LLaMA, Falcon, Mistral, etc.) em domÃ­nio mÃ©dico.

## ğŸ“– VisÃ£o Geral

O processo de prÃ©-processamento transforma o dataset mÃ©dico bruto (`ori_pqal.json`) do PubMedQA em um formato estruturado adequado para **Instruction Tuning**, garantindo:

- âœ… **AnonimizaÃ§Ã£o** de dados sensÃ­veis (conformidade LGPD/HIPAA)
- âœ… **FormataÃ§Ã£o** em estrutura de instruÃ§Ã£o para modelos LLM
- âœ… **ValidaÃ§Ã£o** de qualidade e integridade dos dados
- âœ… **Enriquecimento** com termos tÃ©cnicos mÃ©dicos (MESH)

---

## ğŸ“ Estrutura do Projeto

```
fine_tuning/
â”œâ”€â”€ prepare-medical-data.ipynb    # Notebook Jupyter com pipeline completo
â”œâ”€â”€ data_processor.py              # Script Python modular para processamento
â”œâ”€â”€ validate_data.py               # Script de validaÃ§Ã£o de dados
â”œâ”€â”€ run_pipeline.py                # Pipeline completo (processamento + validaÃ§Ã£o)
â”œâ”€â”€ medical_tuning_data.json       # Dataset processado (gerado apÃ³s execuÃ§Ã£o)
â””â”€â”€ README.md                      # Este arquivo
```

---

## ğŸ”„ Pipeline de PrÃ©-Processamento

O pipeline Ã© composto por **6 etapas sequenciais**:

### Etapa 0: ImportaÃ§Ã£o de Bibliotecas
- Importa `json`, `re` e `Path` necessÃ¡rios para o processamento

### Etapa 1: Carregamento do Dataset
- LÃª o arquivo `ori_pqal.json` do PubMedQA
- Estrutura: `{id_artigo: {QUESTION, CONTEXTS, LONG_ANSWER, MESHES, ...}}`
- Valida estrutura e exibe estatÃ­sticas iniciais

### Etapa 2: AnonimizaÃ§Ã£o de Dados SensÃ­veis
- Remove padrÃµes que possam identificar pacientes:
  - **Datas**: `15/03/2024` â†’ `[DATA]`
  - **IDs de pacientes**: `ID: 12345` â†’ `ID: [PACIENTE_ID]`
  - **Telefones**: `11987654321` â†’ `[TELEFONE]`
  - **Emails**: `email@hospital.com` â†’ `[EMAIL]`

### Etapa 3: FormataÃ§Ã£o para Instruction Tuning
- Transforma dados brutos em formato de instruÃ§Ã£o
- Estrutura do prompt:
  ```
  INSTRUÃ‡ÃƒO MÃ‰DICA: Responda Ã  pergunta baseando-se nos contextos fornecidos.
  [|Contexto|] {contextos anonimizados} [|eContexto|]
  [|Termos|] {termos MESH} [|eTermos|]
  [|Pergunta|] {pergunta} [|ePergunta|]
  [|Resposta|] {resposta anonimizada} [|eResposta|]
  ```

### Etapa 4: Processamento Completo
- Processa todas as entradas do dataset
- Aplica anonimizaÃ§Ã£o e formataÃ§Ã£o
- Tratamento de erros robusto

### Etapa 5: Salvamento do Dataset
- Salva dados processados em `medical_tuning_data.json`
- Formato JSON com indentaÃ§Ã£o para legibilidade

### Etapa 6: VerificaÃ§Ã£o Final
- Visualiza amostra dos dados processados
- Valida formato e qualidade

---

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Notebook Jupyter (Recomendado para ExploraÃ§Ã£o)

Ideal para entender o processo passo a passo e fazer ajustes:

```bash
cd fine_tuning
jupyter notebook prepare-medical-data.ipynb
```

**Vantagens:**
- VisualizaÃ§Ã£o interativa de cada etapa
- Facilita debugging e ajustes
- ComentÃ¡rios detalhados em cada cÃ©lula

**Ordem de execuÃ§Ã£o:**
1. Execute as cÃ©lulas **sequencialmente** (de cima para baixo)
2. Aguarde o processamento completo
3. Verifique os resultados na Ãºltima cÃ©lula

### OpÃ§Ã£o 2: Script Python Individual

Para processar apenas os dados:

```bash
cd fine_tuning
python data_processor.py
```

**SaÃ­da:** `medical_tuning_data.json`

### OpÃ§Ã£o 3: Pipeline Completo (Recomendado para ProduÃ§Ã£o)

Executa processamento + validaÃ§Ã£o automaticamente:

```bash
cd fine_tuning
python run_pipeline.py
```

**Vantagens:**
- Processamento e validaÃ§Ã£o em uma Ãºnica execuÃ§Ã£o
- RelatÃ³rio completo de estatÃ­sticas
- VerificaÃ§Ã£o automÃ¡tica de erros

### OpÃ§Ã£o 4: ValidaÃ§Ã£o Separada

Para validar dados jÃ¡ processados:

```bash
cd fine_tuning
python validate_data.py
```

**SaÃ­da:** RelatÃ³rio detalhado com estatÃ­sticas e validaÃ§Ãµes

---

## ğŸ“Š Formato dos Dados

### Entrada (ori_pqal.json)

```json
{
  "21645374": {
    "QUESTION": "Do mitochondria play a role in remodelling lace plant leaves?",
    "CONTEXTS": [
      "Programmed cell death (PCD) is the regulated death...",
      "The following paper elucidates the role..."
    ],
    "LONG_ANSWER": "Results depicted mitochondrial dynamics...",
    "MESHES": ["Mitochondria", "Apoptosis", "Cell Differentiation"],
    "YEAR": "2011"
  }
}
```

### SaÃ­da (medical_tuning_data.json)

```json
[
  {
    "id": "21645374",
    "input": "INSTRUÃ‡ÃƒO MÃ‰DICA: Responda Ã  pergunta baseando-se nos contextos fornecidos.\n[|Contexto|] Programmed cell death (PCD) is the regulated death... [|eContexto|]\n[|Termos|] Mitochondria, Apoptosis, Cell Differentiation [|eTermos|]\n[|Pergunta|] Do mitochondria play a role in remodelling lace plant leaves? [|ePergunta|]\n\n[|Resposta|] Results depicted mitochondrial dynamics... [|eResposta|]"
  }
]
```

---

## ğŸ”’ AnonimizaÃ§Ã£o de Dados

### PadrÃµes Identificados e SubstituÃ­dos

| PadrÃ£o Original | Placeholder | Exemplo |
|----------------|-------------|---------|
| Datas (DD/MM/YYYY) | `[DATA]` | `15/03/2024` â†’ `[DATA]` |
| Datas (YYYY-MM-DD) | `[DATA]` | `2024-03-15` â†’ `[DATA]` |
| IDs de pacientes | `[PACIENTE_ID]` | `ID: 12345` â†’ `ID: [PACIENTE_ID]` |
| Telefones | `[TELEFONE]` | `11987654321` â†’ `[TELEFONE]` |
| Emails | `[EMAIL]` | `email@hospital.com` â†’ `[EMAIL]` |

### Conformidade Legal

- âœ… **LGPD** (Lei Geral de ProteÃ§Ã£o de Dados - Brasil)
- âœ… **HIPAA** (Health Insurance Portability and Accountability Act - EUA)
- âœ… ProteÃ§Ã£o de dados pessoais de pacientes
- âœ… PrevenÃ§Ã£o de vazamento de informaÃ§Ãµes sensÃ­veis

---

## ğŸ“ Componentes do Prompt Formatado

Cada entrada processada contÃ©m:

### 1. InstruÃ§Ã£o Geral
```
INSTRUÃ‡ÃƒO MÃ‰DICA: Responda Ã  pergunta baseando-se nos contextos fornecidos.
```

### 2. Contexto CientÃ­fico
```
[|Contexto|] {evidÃªncias cientÃ­ficas dos artigos PubMed} [|eContexto|]
```
- MÃºltiplos contextos sÃ£o unidos em um Ãºnico bloco
- Dados sensÃ­veis sÃ£o anonimizados automaticamente

### 3. Termos MESH (Opcional)
```
[|Termos|] {termos tÃ©cnicos mÃ©dicos separados por vÃ­rgula} [|eTermos|]
```
- Medical Subject Headings (vocabulÃ¡rio controlado)
- Ajuda o modelo a entender o domÃ­nio mÃ©dico

### 4. Pergunta
```
[|Pergunta|] {questÃ£o mÃ©dica a ser respondida} [|ePergunta|]
```

### 5. Resposta Esperada
```
[|Resposta|] {resposta longa baseada nas evidÃªncias} [|eResposta|]
```
- Resposta Ã© anonimizada para proteÃ§Ã£o de dados

---

## âœ… ValidaÃ§Ã£o de Dados

O script `validate_data.py` verifica:

- âœ… Estrutura correta (presenÃ§a de campos `id` e `input`)
- âœ… Tamanho mÃ©dio, mÃ­nimo e mÃ¡ximo dos inputs
- âœ… PresenÃ§a de componentes obrigatÃ³rios:
  - Delimitadores `[|Contexto|]`, `[|Pergunta|]`, `[|Resposta|]`
- âœ… ConsistÃªncia entre entradas
- âœ… IdentificaÃ§Ã£o de erros e inconsistÃªncias

**Exemplo de saÃ­da:**
```
================================================================================
RELATÃ“RIO DE VALIDAÃ‡ÃƒO DO DATASET
================================================================================

ğŸ“Š EstatÃ­sticas Gerais:
  Total de entradas: 1000
  Entradas com ID: 1000
  Entradas com input: 1000

ğŸ“ EstatÃ­sticas de Tamanho:
  Tamanho mÃ©dio do input: 1250 caracteres
  Tamanho mÃ­nimo: 450 caracteres
  Tamanho mÃ¡ximo: 3200 caracteres

âœ… Componentes Presentes:
  Entradas com contexto: 1000
  Entradas com pergunta: 1000
  Entradas com resposta: 1000

âœ… Nenhum erro encontrado!
```

---

## ğŸ”§ ConfiguraÃ§Ã£o e Requisitos

### Requisitos do Sistema

- Python 3.7+
- Bibliotecas padrÃ£o: `json`, `re`, `pathlib`
- Jupyter Notebook (opcional, para uso do notebook)

### Estrutura de DiretÃ³rios Esperada

```
tech_challenge_fase_3_v2/
â”œâ”€â”€ context/
â”‚   â””â”€â”€ pubmedqa-master/
â”‚       â””â”€â”€ data/
â”‚           â””â”€â”€ ori_pqal.json      # Dataset original
â””â”€â”€ fine_tuning/
    â”œâ”€â”€ prepare-medical-data.ipynb
    â”œâ”€â”€ data_processor.py
    â”œâ”€â”€ validate_data.py
    â””â”€â”€ run_pipeline.py
```

### Ajustando Caminhos

Se o dataset estiver em outro local, ajuste o caminho em:

**No notebook:**
```python
input_file = '../context/pubmedqa-master/data/ori_pqal.json'
```

**Nos scripts Python:**
```python
input_file = '../context/pubmedqa-master/data/ori_pqal.json'
```

---

## ğŸ“ˆ EstatÃ­sticas e Performance

### Tempo de Processamento

- **Dataset pequeno** (< 1.000 entradas): ~30 segundos
- **Dataset mÃ©dio** (1.000 - 10.000 entradas): ~2-5 minutos
- **Dataset grande** (> 10.000 entradas): ~10-30 minutos

### Uso de MemÃ³ria

- Depende do tamanho do dataset
- Recomendado: mÃ­nimo 4GB RAM disponÃ­vel
- Para datasets muito grandes, considere processamento em lotes

### Taxa de Sucesso

- Esperado: > 99% de entradas processadas com sucesso
- Entradas com erro sÃ£o registradas mas nÃ£o interrompem o processamento

---

## ğŸ› Troubleshooting

### Erro: Arquivo nÃ£o encontrado

```
Erro: Arquivo nÃ£o encontrado: ../context/pubmedqa-master/data/ori_pqal.json
```

**SoluÃ§Ã£o:** Verifique o caminho do arquivo e ajuste se necessÃ¡rio.

### Erro: MemÃ³ria insuficiente

**SoluÃ§Ã£o:** Processe o dataset em lotes ou aumente a memÃ³ria disponÃ­vel.

### Erro: Encoding UTF-8

**SoluÃ§Ã£o:** Certifique-se de que o arquivo estÃ¡ em UTF-8. O script jÃ¡ trata isso automaticamente.

### ValidaÃ§Ã£o mostra erros

**SoluÃ§Ã£o:** 
1. Verifique os logs de processamento
2. Revise as entradas com erro
3. Execute novamente o processamento

---

## ğŸ”„ PrÃ³ximos Passos ApÃ³s PrÃ©-Processamento

ApÃ³s concluir o prÃ©-processamento:

### 1. Validar Dados
```bash
python validate_data.py
```

### 2. Preparar para Fine-Tuning

Use o arquivo `medical_tuning_data.json` com:

- **Hugging Face Transformers**
  ```python
  from datasets import load_dataset
  dataset = load_dataset('json', data_files='medical_tuning_data.json')
  ```

- **PEFT (LoRA/QLoRA)**
  - ConfiguraÃ§Ã£o de adaptadores para treinamento eficiente

- **Axolotl**
  - Framework especializado em fine-tuning de LLMs

- **Outras ferramentas**
  - Qualquer framework que aceite formato JSON de instruÃ§Ãµes

### 3. Configurar HiperparÃ¢metros

- Learning rate: `1e-4` a `5e-4`
- Batch size: 4-16 (depende da GPU)
- Epochs: 1-3 (evitar overfitting)
- LoRA rank: 8-64

---

## ğŸ“š ReferÃªncias e Recursos

### Dataset Original
- **PubMedQA**: Dataset de perguntas e respostas mÃ©dicas baseadas em evidÃªncias
- LocalizaÃ§Ã£o: `../context/pubmedqa-master/data/ori_pqal.json`
- Mais informaÃ§Ãµes: [PubMedQA Paper](https://arxiv.org/abs/1909.06146)

### Notebooks de ReferÃªncia
- `../context/prepare-data.ipynb` - PreparaÃ§Ã£o de dados de notÃ­cias
- `../context/generate-output-for-news.ipynb` - GeraÃ§Ã£o de saÃ­das

### DocumentaÃ§Ã£o TÃ©cnica
- **Instruction Tuning**: TÃ©cnica de fine-tuning para modelos LLM
- **LGPD**: Lei Geral de ProteÃ§Ã£o de Dados (Brasil)
- **HIPAA**: Health Insurance Portability and Accountability Act (EUA)
- **MESH**: Medical Subject Headings (vocabulÃ¡rio controlado)

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

1. Verifique a seÃ§Ã£o **Troubleshooting** acima
2. Revise os comentÃ¡rios detalhados no notebook
3. Execute `validate_data.py` para diagnosticar problemas
4. Verifique os logs de processamento

---

## ğŸ“„ LicenÃ§a

Este cÃ³digo faz parte do projeto Medical Assistant e segue as mesmas diretrizes de licenciamento do projeto principal.

---

**Ãšltima atualizaÃ§Ã£o:** 2024

**VersÃ£o do pipeline:** 1.0
