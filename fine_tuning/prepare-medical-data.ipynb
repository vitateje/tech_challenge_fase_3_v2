{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepara√ß√£o de Dados M√©dicos para Fine-Tuning\n",
        "\n",
        "Este notebook processa o dataset `ori_pqal.json` para criar dados formatados para fine-tuning de modelos LLM (LLaMA/Falcon) em dom√≠nio m√©dico.\n",
        "\n",
        "## üìã Objetivos do Pipeline:\n",
        "\n",
        "1. **Carregamento**: Ler o dataset m√©dico original (ori_pqal.json) com estrutura complexa\n",
        "2. **Anonimiza√ß√£o**: Remover dados sens√≠veis (datas, IDs, telefones, emails) para conformidade com LGPD/HIPAA\n",
        "3. **Transforma√ß√£o**: Converter estrutura JSON aninhada em formato de instru√ß√£o para fine-tuning\n",
        "4. **Valida√ß√£o**: Verificar integridade e qualidade dos dados processados\n",
        "5. **Exporta√ß√£o**: Salvar dataset processado em formato JSON pronto para treinamento\n",
        "\n",
        "## üîÑ Ordem de Execu√ß√£o:\n",
        "\n",
        "Execute as c√©lulas **sequencialmente** (de cima para baixo) para garantir que todas as depend√™ncias estejam carregadas corretamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 0: IMPORTA√á√ÉO DE BIBLIOTECAS\n",
        "# ============================================================================\n",
        "# Esta c√©lula importa todas as bibliotecas necess√°rias para o processamento\n",
        "# Execute esta c√©lula PRIMEIRO antes de qualquer outra opera√ß√£o\n",
        "\n",
        "import json      # Para leitura e escrita de arquivos JSON\n",
        "import re        # Para express√µes regulares (anonimiza√ß√£o de dados)\n",
        "from pathlib import Path  # Para manipula√ß√£o de caminhos de arquivos\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
        "print(\"   - json: Para manipula√ß√£o de arquivos JSON\")\n",
        "print(\"   - re: Para anonimiza√ß√£o com express√µes regulares\")\n",
        "print(\"   - Path: Para gerenciamento de caminhos de arquivos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 1: CARREGAMENTO DO DATASET ORIGINAL\n",
        "# ============================================================================\n",
        "# Esta etapa l√™ o arquivo ori_pqal.json que cont√©m dados m√©dicos estruturados\n",
        "# do PubMedQA (dataset de perguntas e respostas m√©dicas baseadas em evid√™ncias)\n",
        "#\n",
        "# Estrutura do dataset:\n",
        "#   - Chave: ID √∫nico do artigo PubMed (ex: \"21645374\")\n",
        "#   - Valor: Objeto com QUESTION, CONTEXTS, LONG_ANSWER, MESHES, etc.\n",
        "#\n",
        "# IMPORTANTE: Execute esta c√©lula ANTES de processar os dados\n",
        "\n",
        "def load_medical_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Carrega o dataset m√©dico do arquivo JSON\n",
        "    \n",
        "    Args:\n",
        "        file_path: Caminho relativo ou absoluto para o arquivo ori_pqal.json\n",
        "        \n",
        "    Returns:\n",
        "        Dicion√°rio Python com estrutura: {id_artigo: {QUESTION, CONTEXTS, ...}}\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Define o caminho para o dataset original\n",
        "# Ajuste este caminho se o arquivo estiver em outro local\n",
        "input_file = '../context/pubmedqa-master/data/ori_pqal.json'\n",
        "\n",
        "# Carrega todos os dados do arquivo JSON na mem√≥ria\n",
        "# Isso pode levar alguns segundos dependendo do tamanho do arquivo\n",
        "raw_data = load_medical_dataset(input_file)\n",
        "\n",
        "# Exibe informa√ß√µes sobre o dataset carregado\n",
        "print(\"=\" * 80)\n",
        "print(\"üì¶ DATASET CARREGADO COM SUCESSO\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total de entradas m√©dicas: {len(raw_data)}\")\n",
        "print(f\"Exemplo de ID (chave): {list(raw_data.keys())[0]}\")\n",
        "print(f\"\\nEstrutura de uma entrada:\")\n",
        "sample_key = list(raw_data.keys())[0]\n",
        "sample_entry = raw_data[sample_key]\n",
        "print(f\"  - QUESTION: {sample_entry.get('QUESTION', 'N/A')[:80]}...\")\n",
        "print(f\"  - CONTEXTS: {len(sample_entry.get('CONTEXTS', []))} contextos\")\n",
        "print(f\"  - LONG_ANSWER: {len(sample_entry.get('LONG_ANSWER', ''))} caracteres\")\n",
        "print(f\"  - MESHES: {len(sample_entry.get('MESHES', []))} termos\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 2: FUN√á√ÉO DE ANONIMIZA√á√ÉO DE DADOS SENS√çVEIS\n",
        "# ============================================================================\n",
        "# Esta etapa define a fun√ß√£o que remove informa√ß√µes que possam identificar\n",
        "# pacientes ou violar privacidade (conformidade com LGPD/HIPAA)\n",
        "#\n",
        "# Por que anonimizar?\n",
        "#   - Prote√ß√£o de dados pessoais (LGPD no Brasil, HIPAA nos EUA)\n",
        "#   - Preven√ß√£o de vazamento de informa√ß√µes sens√≠veis\n",
        "#   - Necess√°rio para ambientes hospitalares e pesquisa m√©dica\n",
        "#\n",
        "# IMPORTANTE: Esta fun√ß√£o ser√° usada em TODAS as etapas de processamento\n",
        "#             que envolvem texto com dados de pacientes\n",
        "\n",
        "def anonymize_text(text):\n",
        "    \"\"\"\n",
        "    Anonimiza texto removendo padr√µes que possam identificar pacientes\n",
        "    \n",
        "    Esta fun√ß√£o usa express√µes regulares (regex) para encontrar e substituir:\n",
        "    - Datas espec√≠ficas ‚Üí [DATA]\n",
        "    - IDs de pacientes ‚Üí [PACIENTE_ID]\n",
        "    - Telefones ‚Üí [TELEFONE]\n",
        "    - Emails ‚Üí [EMAIL]\n",
        "    \n",
        "    Args:\n",
        "        text: String de texto que pode conter dados sens√≠veis\n",
        "        \n",
        "    Returns:\n",
        "        String com dados sens√≠veis substitu√≠dos por placeholders gen√©ricos\n",
        "    \"\"\"\n",
        "    # Verifica se o texto √© uma string v√°lida\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "    \n",
        "    # PATTERN 1: Remove datas no formato DD/MM/YYYY ou MM/DD/YYYY\n",
        "    # Exemplo: \"15/03/2024\" ou \"03/15/2024\" ‚Üí \"[DATA]\"\n",
        "    text = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{4}', '[DATA]', text)\n",
        "    \n",
        "    # PATTERN 2: Remove datas no formato ISO (YYYY-MM-DD)\n",
        "    # Exemplo: \"2024-03-15\" ‚Üí \"[DATA]\"\n",
        "    text = re.sub(r'\\d{4}-\\d{2}-\\d{2}', '[DATA]', text)\n",
        "    \n",
        "    # PATTERN 3: Remove IDs de pacientes (formato \"ID: 12345\" ou \"Patient ID: 12345\")\n",
        "    # Exemplo: \"ID: 12345\" ‚Üí \"ID: [PACIENTE_ID]\"\n",
        "    # flags=re.IGNORECASE torna a busca case-insensitive (mai√∫sculas/min√∫sculas)\n",
        "    text = re.sub(r'ID:\\s*\\d+', 'ID: [PACIENTE_ID]', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'Patient ID:\\s*\\d+', 'Patient ID: [PACIENTE_ID]', text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # PATTERN 4: Remove n√∫meros de telefone (formato XXX-XXX-XXXX ou XXX.XXX.XXXX)\n",
        "    # Exemplo: \"11987654321\" ou \"11-98765-4321\" ‚Üí \"[TELEFONE]\"\n",
        "    text = re.sub(r'\\d{3}[-.]?\\d{3}[-.]?\\d{4}', '[TELEFONE]', text)\n",
        "    \n",
        "    # PATTERN 5: Remove endere√ßos de email\n",
        "    # Exemplo: \"email@hospital.com\" ‚Üí \"[EMAIL]\"\n",
        "    # \\b garante que estamos no in√≠cio/fim de uma palavra\n",
        "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# ============================================================================\n",
        "# TESTE DA FUN√á√ÉO DE ANONIMIZA√á√ÉO\n",
        "# ============================================================================\n",
        "# Testa a fun√ß√£o com um exemplo real para verificar se est√° funcionando\n",
        "# corretamente antes de aplicar em todo o dataset\n",
        "\n",
        "test_text = \"Paciente ID: 12345 foi atendido em 15/03/2024. Contato: 11987654321 ou email@hospital.com\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üîí TESTE DE ANONIMIZA√á√ÉO\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Texto original:\")\n",
        "print(f\"  {test_text}\")\n",
        "print(\"\\nTexto anonimizado:\")\n",
        "print(f\"  {anonymize_text(test_text)}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚úÖ Fun√ß√£o de anonimiza√ß√£o testada e pronta para uso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 3: FORMATA√á√ÉO PARA INSTRUCTION TUNING\n",
        "# ============================================================================\n",
        "# Esta etapa transforma os dados m√©dicos brutos em formato de instru√ß√£o\n",
        "# adequado para fine-tuning de modelos LLM (LLaMA, Falcon, etc.)\n",
        "#\n",
        "# O que √© Instruction Tuning?\n",
        "#   - T√©cnica de fine-tuning onde o modelo aprende a seguir instru√ß√µes\n",
        "#   - Formato: INSTRU√á√ÉO ‚Üí ENTRADA ‚Üí SA√çDA ESPERADA\n",
        "#   - Permite que o modelo aprenda a responder perguntas baseadas em contexto\n",
        "#\n",
        "# Formato usado (inspirado nos notebooks de refer√™ncia):\n",
        "#   [|Contexto|] ... [|eContexto|]  ‚Üí Delimitadores para contexto m√©dico\n",
        "#   [|Pergunta|] ... [|ePergunta|]  ‚Üí Delimitadores para pergunta\n",
        "#   [|Resposta|] ... [|eResposta|]   ‚Üí Delimitadores para resposta esperada\n",
        "#\n",
        "# IMPORTANTE: Esta fun√ß√£o deve ser executada DEPOIS de definir anonymize_text()\n",
        "#             pois ela usa essa fun√ß√£o para proteger dados sens√≠veis\n",
        "\n",
        "def prepare_medical_instruction(data_id, content):\n",
        "    \"\"\"\n",
        "    Prepara uma entrada do dataset no formato de instru√ß√£o para fine-tuning\n",
        "    \n",
        "    Esta fun√ß√£o:\n",
        "    1. Extrai QUESTION, CONTEXTS, LONG_ANSWER e MESHES do conte√∫do\n",
        "    2. Une m√∫ltiplos contextos em um √∫nico bloco de texto\n",
        "    3. Aplica anonimiza√ß√£o em contextos e respostas\n",
        "    4. Formata tudo em um prompt estruturado com delimitadores\n",
        "    \n",
        "    Args:\n",
        "        data_id: ID √∫nico do artigo PubMed (chave do dicion√°rio original)\n",
        "        content: Dicion√°rio com QUESTION, CONTEXTS, LONG_ANSWER, MESHES, etc.\n",
        "        \n",
        "    Returns:\n",
        "        Dicion√°rio com:\n",
        "          - \"id\": ID do artigo\n",
        "          - \"input\": String formatada pronta para fine-tuning\n",
        "    \"\"\"\n",
        "    # PASSO 1: Extrai os campos principais do conte√∫do m√©dico\n",
        "    question = content.get(\"QUESTION\", \"\")           # Pergunta m√©dica a ser respondida\n",
        "    contexts = content.get(\"CONTEXTS\", [])            # Lista de contextos cient√≠ficos (evid√™ncias)\n",
        "    long_answer = content.get(\"LONG_ANSWER\", \"\")      # Resposta longa baseada nas evid√™ncias\n",
        "    meshes = content.get(\"MESHES\", [])               # Termos t√©cnicos (Medical Subject Headings)\n",
        "    \n",
        "    # PASSO 2: Consolida m√∫ltiplos contextos em um √∫nico bloco de texto\n",
        "    # O dataset pode ter v√°rios contextos (fragmentos de artigos cient√≠ficos)\n",
        "    # Juntamos todos em uma √∫nica string para facilitar o aprendizado do modelo\n",
        "    context_str = \" \".join(contexts)\n",
        "    \n",
        "    # PASSO 3: Formata termos MESH como string separada por v√≠rgulas\n",
        "    # MESH s√£o termos t√©cnicos que ajudam o modelo a entender o dom√≠nio\n",
        "    # Exemplo: [\"Mitochondria\", \"Apoptosis\", \"Cell Differentiation\"]\n",
        "    meshes_str = \", \".join(meshes) if meshes else \"\"\n",
        "    \n",
        "    # PASSO 4: Constr√≥i o prompt formatado seguindo o padr√£o dos notebooks de refer√™ncia\n",
        "    # Formato inspirado em: [|News|]...[|eNews|] adaptado para medicina\n",
        "    # \n",
        "    # Estrutura do prompt:\n",
        "    #   INSTRU√á√ÉO M√âDICA: [instru√ß√£o geral]\n",
        "    #   [|Contexto|] [contextos anonimizados] [|eContexto|]\n",
        "    #   [|Termos|] [termos MESH] [|eTermos|]  (opcional)\n",
        "    #   [|Pergunta|] [pergunta] [|ePergunta|]\n",
        "    #   [|Resposta|] [resposta anonimizada] [|eResposta|]\n",
        "    \n",
        "    formatted_input = (\n",
        "        f\"INSTRU√á√ÉO M√âDICA: Responda √† pergunta baseando-se nos contextos fornecidos.\\n\"\n",
        "        f\"[|Contexto|] {anonymize_text(context_str)}[|eContexto|]\\n\"\n",
        "    )\n",
        "    \n",
        "    # Adiciona termos MESH apenas se existirem (opcional, mas enriquece o contexto)\n",
        "    if meshes_str:\n",
        "        formatted_input += f\"[|Termos|] {meshes_str}[|eTermos|]\\n\"\n",
        "    \n",
        "    # Adiciona pergunta e resposta (a resposta √© anonimizada para prote√ß√£o de dados)\n",
        "    formatted_input += (\n",
        "        f\"[|Pergunta|] {question}[|ePergunta|]\\n\\n\"\n",
        "        f\"[|Resposta|]{anonymize_text(long_answer)}[|eResposta|]\"\n",
        "    )\n",
        "    \n",
        "    # Retorna estrutura padronizada para o dataset de fine-tuning\n",
        "    return {\n",
        "        \"id\": data_id,\n",
        "        \"input\": formatted_input\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# TESTE DA FUN√á√ÉO DE FORMATA√á√ÉO\n",
        "# ============================================================================\n",
        "# Testa a fun√ß√£o com uma entrada real do dataset para verificar o formato\n",
        "# antes de processar todas as entradas (economiza tempo e recursos)\n",
        "\n",
        "sample_id = list(raw_data.keys())[0]      # Pega o primeiro ID dispon√≠vel\n",
        "sample_content = raw_data[sample_id]      # Obt√©m o conte√∫do desse ID\n",
        "sample_processed = prepare_medical_instruction(sample_id, sample_content)  # Processa\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìù EXEMPLO DE ENTRADA PROCESSADA\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ID do artigo: {sample_processed['id']}\")\n",
        "print(f\"\\nFormato do input (primeiros 500 caracteres):\")\n",
        "print(\"-\" * 80)\n",
        "print(sample_processed[\"input\"][:500] + \"...\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"Tamanho total do input: {len(sample_processed['input'])} caracteres\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚úÖ Fun√ß√£o de formata√ß√£o testada e pronta para processar todo o dataset!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 4: PROCESSAMENTO COMPLETO DO DATASET\n",
        "# ============================================================================\n",
        "# Esta etapa processa TODAS as entradas do dataset original, aplicando:\n",
        "#   - Anonimiza√ß√£o de dados sens√≠veis\n",
        "#   - Formata√ß√£o em estrutura de instru√ß√£o\n",
        "#   - Tratamento de erros para garantir robustez\n",
        "#\n",
        "# IMPORTANTE: Esta etapa pode levar v√°rios minutos dependendo do tamanho\n",
        "#             do dataset. Para datasets grandes, considere processar em lotes.\n",
        "#\n",
        "# IMPORTANTE: Execute esta c√©lula APENAS DEPOIS de:\n",
        "#             1. Carregar o dataset (Etapa 1)\n",
        "#             2. Definir anonymize_text() (Etapa 2)\n",
        "#             3. Definir prepare_medical_instruction() (Etapa 3)\n",
        "\n",
        "# Inicializa lista vazia para armazenar dados processados\n",
        "processed_data = []\n",
        "\n",
        "# Exibe informa√ß√µes sobre o processamento que ser√° realizado\n",
        "total_entries = len(raw_data)\n",
        "print(\"=\" * 80)\n",
        "print(\"üîÑ INICIANDO PROCESSAMENTO COMPLETO DO DATASET\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total de entradas a processar: {total_entries}\")\n",
        "print(f\"Este processo pode levar alguns minutos...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Itera sobre cada entrada do dataset original\n",
        "# raw_data.items() retorna pares (id, conte√∫do) para cada artigo m√©dico\n",
        "for data_id, content in raw_data.items():\n",
        "    try:\n",
        "        # Aplica a fun√ß√£o de formata√ß√£o definida na Etapa 3\n",
        "        # Esta fun√ß√£o j√° inclui anonimiza√ß√£o automaticamente\n",
        "        entry = prepare_medical_instruction(data_id, content)\n",
        "        \n",
        "        # Adiciona a entrada processada √† lista\n",
        "        processed_data.append(entry)\n",
        "        \n",
        "        # Exibe progresso a cada 1000 entradas processadas (opcional, para feedback)\n",
        "        if len(processed_data) % 1000 == 0:\n",
        "            progress = (len(processed_data) / total_entries) * 100\n",
        "            print(f\"Progresso: {len(processed_data)}/{total_entries} ({progress:.1f}%)\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        # Tratamento de erros: se uma entrada falhar, registra o erro mas continua\n",
        "        # Isso garante que o processamento n√£o pare por causa de uma entrada problem√°tica\n",
        "        print(f\"‚ö†Ô∏è  Erro ao processar entrada {data_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Exibe resumo final do processamento\n",
        "print(\"-\" * 80)\n",
        "print(\"=\" * 80)\n",
        "print(\"‚úÖ PROCESSAMENTO CONCLU√çDO\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Entradas processadas com sucesso: {len(processed_data)}\")\n",
        "print(f\"Taxa de sucesso: {(len(processed_data)/total_entries)*100:.2f}%\")\n",
        "print(f\"Entradas com erro: {total_entries - len(processed_data)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 5: SALVAMENTO DO DATASET DE TREINO\n",
        "# ============================================================================\n",
        "# Esta etapa salva o dataset processado em um arquivo JSON que ser√° usado\n",
        "# diretamente no processo de fine-tuning do modelo LLM\n",
        "#\n",
        "# Formato do arquivo de sa√≠da:\n",
        "#   [\n",
        "#     {\n",
        "#       \"id\": \"21645374\",\n",
        "#       \"input\": \"INSTRU√á√ÉO M√âDICA: ... [|Contexto|] ... [|eContexto|] ...\"\n",
        "#     },\n",
        "#     ...\n",
        "#   ]\n",
        "#\n",
        "# IMPORTANTE: Execute esta c√©lula APENAS DEPOIS de processar todos os dados (Etapa 4)\n",
        "#             Caso contr√°rio, o arquivo ser√° salvo vazio ou incompleto\n",
        "\n",
        "# Define o nome do arquivo de sa√≠da\n",
        "# Este arquivo ser√° criado no mesmo diret√≥rio do notebook\n",
        "output_file = 'medical_tuning_data.json'\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üíæ SALVANDO DATASET PROCESSADO\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Arquivo de destino: {output_file}\")\n",
        "print(f\"Total de entradas a salvar: {len(processed_data)}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Abre o arquivo em modo de escrita ('w') com encoding UTF-8\n",
        "# UTF-8 √© necess√°rio para suportar caracteres especiais e acentos\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    # json.dump() escreve a lista de dados processados no arquivo\n",
        "    # indent=2: formata o JSON com indenta√ß√£o de 2 espa√ßos (melhora legibilidade)\n",
        "    # ensure_ascii=False: preserva caracteres n√£o-ASCII (acentos, etc.)\n",
        "    json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Verifica se o arquivo foi criado e exibe informa√ß√µes\n",
        "import os\n",
        "file_size = os.path.getsize(output_file) / (1024 * 1024)  # Tamanho em MB\n",
        "\n",
        "print(\"‚úÖ Dataset salvo com sucesso!\")\n",
        "print(f\"   Arquivo: {output_file}\")\n",
        "print(f\"   Total de entradas: {len(processed_data)}\")\n",
        "print(f\"   Tamanho do arquivo: {file_size:.2f} MB\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nüìå PR√ìXIMOS PASSOS:\")\n",
        "print(\"   1. Valide os dados com: python validate_data.py\")\n",
        "print(\"   2. Use este arquivo para fine-tuning com Hugging Face, PEFT, etc.\")\n",
        "print(\"   3. Configure hiperpar√¢metros de treinamento apropriados\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 6: VERIFICA√á√ÉO FINAL E VISUALIZA√á√ÉO\n",
        "# ============================================================================\n",
        "# Esta etapa exibe uma amostra das entradas processadas para verifica√ß√£o\n",
        "# visual da qualidade e formato dos dados\n",
        "#\n",
        "# Por que verificar?\n",
        "#   - Confirma que o formato est√° correto\n",
        "#   - Permite identificar problemas visuais antes do treinamento\n",
        "#   - Ajuda a entender como os dados ser√£o usados pelo modelo\n",
        "#\n",
        "# IMPORTANTE: Esta √© uma etapa opcional, mas recomendada para garantir\n",
        "#             qualidade antes de iniciar o fine-tuning\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üîç VERIFICA√á√ÉO FINAL - AMOSTRA DE DADOS PROCESSADOS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Exibindo as primeiras 3 entradas do dataset processado\")\n",
        "print(f\"(Total de {len(processed_data)} entradas dispon√≠veis)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Itera sobre as primeiras 3 entradas processadas\n",
        "# [:3] pega apenas os primeiros 3 elementos da lista\n",
        "for i, entry in enumerate(processed_data[:3], start=1):\n",
        "    print(f\"\\nüìÑ ENTRADA {i} de 3\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"ID do artigo: {entry['id']}\")\n",
        "    print(f\"Tamanho do input: {len(entry['input'])} caracteres\")\n",
        "    print(f\"\\nPreview do input (primeiros 300 caracteres):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(entry['input'][:300] + \"...\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ Verifica√ß√£o conclu√≠da!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nüí° DICAS:\")\n",
        "print(\"   - Verifique se os delimitadores [|Contexto|], [|Pergunta|], etc. est√£o presentes\")\n",
        "print(\"   - Confirme que dados sens√≠veis foram anonimizados corretamente\")\n",
        "print(\"   - Valide que o formato est√° consistente entre todas as entradas\")\n",
        "print(\"=\" * 80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
