# Pipeline RAG para Dados MÃ©dicos com Pinecone

Sistema completo de ingestÃ£o e RAG (Retrieval-Augmented Generation) para dados mÃ©dicos do dataset PubMedQA usando Pinecone como vector store.

## ğŸ“‹ VisÃ£o Geral

Este pipeline processa dados mÃ©dicos estruturados do arquivo `ori_pqal.json` e os ingere no Pinecone para permitir busca semÃ¢ntica e recuperaÃ§Ã£o de contexto relevante para assistentes mÃ©dicos baseados em IA.

### CaracterÃ­sticas Principais

- âœ… **Processamento completo**: Carregamento, limpeza, anonimizaÃ§Ã£o e chunking de dados mÃ©dicos
- âœ… **IntegraÃ§Ã£o Pinecone**: IngestÃ£o otimizada em lotes com retry logic
- âœ… **MÃºltiplos Providers**: Suporte para Gemini e Ollama embeddings
- âœ… **Modular**: Scripts Python reutilizÃ¡veis e notebooks Jupyter detalhados
- âœ… **Conformidade**: AnonimizaÃ§Ã£o de dados sensÃ­veis (LGPD/HIPAA)
- âœ… **DocumentaÃ§Ã£o**: Notebooks com comentÃ¡rios detalhados em portuguÃªs

## ğŸ—ï¸ Arquitetura

```
ori_pqal.json
    â†“
[Data Loader] â†’ Carrega dados JSON
    â†“
[Data Processor] â†’ Processa e anonimiza
    â†“
[Text Splitter] â†’ Divide em chunks
    â†“
[Embeddings Manager] â†’ Gera embeddings
    â†“
[Pinecone Ingester] â†’ IngestÃ£o em lotes
    â†“
Pinecone Index (biobyia)
    â†“
[RAG Query] â†’ Busca semÃ¢ntica
```

## ğŸ“ Estrutura de Arquivos

```
rag_medical/
â”œâ”€â”€ notebooks/                    # Notebooks Jupyter detalhados
â”‚   â”œâ”€â”€ 01-load-and-explore-data.ipynb
â”‚   â”œâ”€â”€ 02-process-medical-data.ipynb
â”‚   â”œâ”€â”€ 03-embed-and-ingest-pinecone.ipynb
â”‚   â””â”€â”€ 04-test-rag-query.ipynb
â”œâ”€â”€ scripts/                      # Scripts Python modulares
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py           # Carregamento de dados
â”‚   â”œâ”€â”€ data_processor.py        # Processamento e limpeza
â”‚   â”œâ”€â”€ text_splitter.py         # DivisÃ£o em chunks
â”‚   â”œâ”€â”€ embeddings_manager.py    # Gerenciamento de embeddings
â”‚   â”œâ”€â”€ pinecone_ingester.py     # IngestÃ£o no Pinecone
â”‚   â””â”€â”€ rag_query.py             # Queries RAG
â”œâ”€â”€ config/                       # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py              # Gerenciamento de configuraÃ§Ãµes
â”œâ”€â”€ utils/                        # UtilitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ anonymizer.py            # AnonimizaÃ§Ã£o de dados
â”œâ”€â”€ .env.example                  # Template de variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â””â”€â”€ README.md                     # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o

### 1. PrÃ©-requisitos

- Python 3.8 ou superior
- Conta Pinecone (https://app.pinecone.io)
- API Key do Gemini (opcional, mas recomendado) ou Ollama configurado

### 2. Instalar DependÃªncias

```bash
cd rag_medical
pip install -r requirements.txt
```

### 3. Configurar VariÃ¡veis de Ambiente

Copie o arquivo `.env.example` para `.env` e preencha com suas credenciais:

```bash
cp .env.example .env
```

Edite o arquivo `.env`:

```env
# Pinecone Configuration
PINECONE_API_KEY=sua_chave_pinecone_aqui
PINECONE_INDEX_NAME=biobyia
PINECONE_NAMESPACE=medical_qa

# Embeddings Configuration (Gemini - RECOMENDADO)
GEMINI_API_KEY=sua_chave_gemini_aqui
EMBEDDING_MODEL=text-embedding-004

# Data Configuration
MEDICAL_DATA_PATH=../context/pubmedqa-master/data/ori_pqal.json
CHUNK_SIZE=512
CHUNK_OVERLAP=50
```

### 4. Verificar Caminho dos Dados

Certifique-se de que o arquivo `ori_pqal.json` estÃ¡ no caminho especificado em `MEDICAL_DATA_PATH`. O caminho padrÃ£o Ã© relativo ao diretÃ³rio `rag_medical/`.

## ğŸ“– Uso

### ExecuÃ§Ã£o via Notebooks Jupyter (Recomendado)

Execute os notebooks na ordem numÃ©rica:

1. **01-load-and-explore-data.ipynb**
   - Carrega e explora o dataset
   - Valida estrutura dos dados
   - Exibe estatÃ­sticas

2. **02-process-medical-data.ipynb**
   - Processa e anonimiza dados
   - Divide textos em chunks
   - Valida qualidade

3. **03-embed-and-ingest-pinecone.ipynb**
   - Gera embeddings
   - Ingesta dados no Pinecone
   - Verifica ingestÃ£o

4. **04-test-rag-query.ipynb**
   - Testa queries RAG
   - Valida recuperaÃ§Ã£o
   - Exemplos prÃ¡ticos

### ExecuÃ§Ã£o via Scripts Python

```python
from scripts.data_loader import load_medical_dataset
from scripts.data_processor import process_batch
from scripts.text_splitter import create_text_splitter
from scripts.embeddings_manager import EmbeddingsManager
from scripts.pinecone_ingester import PineconeIngester
from config.settings import get_settings

# Carrega configuraÃ§Ãµes
settings = get_settings()

# 1. Carrega dados
raw_data = load_medical_dataset(settings.MEDICAL_DATA_PATH)

# 2. Processa dados
processed_entries = process_batch(raw_data, anonymize=True)

# 3. Divide em chunks
text_splitter = create_text_splitter(
    chunk_size=settings.CHUNK_SIZE,
    chunk_overlap=settings.CHUNK_OVERLAP
)
chunks = text_splitter.split_batch(processed_entries)

# 4. Ingesta no Pinecone
embeddings_manager = EmbeddingsManager()
ingester = PineconeIngester(embeddings_manager=embeddings_manager)
stats = ingester.ingest_chunks(chunks)

# 5. Query RAG
from scripts.rag_query import query_medical_rag
results = query_medical_rag("Do mitochondria play a role?", top_k=5)
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Pinecone

- **Ãndice**: `biobyia` (jÃ¡ criado)
- **DimensÃµes**: 1024 (compatÃ­vel com embeddings de 768 dims)
- **MÃ©trica**: Cosine similarity
- **Namespace**: `medical_qa` (opcional, para separar dados)

### Embeddings

**OpÃ§Ã£o 1: Gemini (Recomendado)**
- Modelo: `text-embedding-004`
- DimensÃµes: 768
- API Key: Obtenha em https://makersuite.google.com/app/apikey

**OpÃ§Ã£o 2: Ollama (Local)**
- Modelo: `mxbai-embed-large` (1024 dims) ou outro compatÃ­vel
- Base URL: `http://localhost:11434`
- Requer Ollama instalado e rodando localmente

### Chunking

- **Chunk Size**: 512 caracteres (padrÃ£o)
- **Chunk Overlap**: 50 caracteres (padrÃ£o)
- Ajuste conforme necessÃ¡rio para otimizar recuperaÃ§Ã£o

## ğŸ“Š Metadados no Pinecone

Cada documento no Pinecone contÃ©m:

```python
{
    "id": "article_21645374_chunk_0",
    "values": [0.123, -0.456, ...],  # Embedding vector
    "metadata": {
        "article_id": "21645374",
        "question": "Do mitochondria play a role?",
        "meshes": "Mitochondria, Apoptosis, ...",
        "year": "2011",
        "chunk_index": 0,
        "source": "pubmedqa",
        "type": "medical_qa",
        "text": "Context: ... Question: ... Answer: ..."
    }
}
```

## ğŸ” Queries RAG

### Query BÃ¡sica

```python
from scripts.rag_query import query_medical_rag

results = query_medical_rag(
    "Do mitochondria play a role in cell death?",
    top_k=5
)
```

### Query com Filtros

```python
results = query_medical_rag(
    "medical research",
    top_k=10,
    filters={"year": "2011"}
)
```

### FormataÃ§Ã£o para LLM

```python
from scripts.rag_query import format_context_for_llm

context = format_context_for_llm(results)
# Usa 'context' no prompt do LLM
```

## ğŸ› Troubleshooting

### Erro: "PINECONE_API_KEY nÃ£o configurada"
- Verifique se o arquivo `.env` existe e contÃ©m `PINECONE_API_KEY`
- Certifique-se de que o arquivo estÃ¡ no diretÃ³rio `rag_medical/`

### Erro: "Arquivo de dados nÃ£o encontrado"
- Verifique o caminho em `MEDICAL_DATA_PATH` no arquivo `.env`
- O caminho Ã© relativo ao diretÃ³rio `rag_medical/`

### Erro: "Nenhum provider de embeddings configurado"
- Configure `GEMINI_API_KEY` ou `OLLAMA_BASE_URL` no arquivo `.env`
- Para Ollama, certifique-se de que estÃ¡ rodando: `ollama serve`

### Embeddings muito lentos
- Use Gemini (mais rÃ¡pido que Ollama)
- Reduza `BATCH_SIZE` se houver rate limiting
- Considere processar em paralelo (futura melhoria)

### IngestÃ£o falhando
- Verifique crÃ©ditos no Pinecone
- Reduza `BATCH_SIZE` para evitar rate limiting
- Verifique logs de erro para detalhes especÃ­ficos

## ğŸ“ˆ Performance

### Tempos Estimados (Dataset ~10.000 entradas)

- **Carregamento**: ~5 segundos
- **Processamento**: ~30 segundos
- **Chunking**: ~10 segundos
- **Embeddings (Gemini)**: ~5-10 minutos
- **IngestÃ£o Pinecone**: ~10-15 minutos
- **Total**: ~20-30 minutos

### OtimizaÃ§Ãµes

- Use Gemini embeddings (mais rÃ¡pido)
- Ajuste `BATCH_SIZE` conforme sua conexÃ£o
- Processe em paralelo para datasets muito grandes

## ğŸ”’ SeguranÃ§a e Privacidade

- **AnonimizaÃ§Ã£o**: Dados sensÃ­veis sÃ£o automaticamente anonimizados
- **LGPD/HIPAA**: Conformidade com regulamentaÃ§Ãµes de privacidade
- **API Keys**: Nunca commite arquivos `.env` no Git
- **Dados**: Use namespace no Pinecone para separar ambientes

## ğŸ“ DecisÃµes de Design

1. **Embeddings**: Gemini text-embedding-004 (768 dims) funciona bem com Ã­ndice de 1024 dims devido Ã  similaridade de cosseno
2. **Chunking**: 512 caracteres com overlap de 50 preserva contexto mÃ©dico
3. **Namespace**: `medical_qa` separa dados mÃ©dicos de outros dados
4. **Metadados**: Estrutura rica permite filtragem e rastreabilidade
5. **Modularidade**: Scripts independentes facilitam manutenÃ§Ã£o e testes

## ğŸ¤ Contribuindo

Para melhorias ou correÃ§Ãµes:
1. Mantenha a estrutura modular
2. Adicione comentÃ¡rios em portuguÃªs
3. Atualize documentaÃ§Ã£o
4. Teste com dataset completo

## ğŸ“„ LicenÃ§a

Este projeto faz parte do sistema de assistente mÃ©dico. Consulte a licenÃ§a do projeto principal.

## ğŸ™ Agradecimentos

- Dataset PubMedQA: https://pubmedqa.github.io/
- Pinecone: https://www.pinecone.io/
- LangChain: https://www.langchain.com/
- Google Gemini: https://ai.google.dev/

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique a seÃ§Ã£o Troubleshooting
2. Consulte os notebooks para exemplos
3. Revise os comentÃ¡rios nos scripts

---

**Desenvolvido para o sistema de assistente mÃ©dico - Tech Challenge Fase 3**

