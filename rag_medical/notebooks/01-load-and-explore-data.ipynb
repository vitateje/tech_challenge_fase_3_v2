{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 01: Carregamento e ExploraÃ§Ã£o de Dados MÃ©dicos\n",
        "\n",
        "Este notebook Ã© o primeiro passo do pipeline RAG para dados mÃ©dicos. Aqui vamos:\n",
        "\n",
        "1. **Carregar** o dataset `ori_pqal.json` do PubMedQA\n",
        "2. **Explorar** a estrutura dos dados (QUESTION, CONTEXTS, LONG_ANSWER, MESHES)\n",
        "3. **Analisar** estatÃ­sticas bÃ¡sicas do dataset\n",
        "4. **Visualizar** exemplos de entradas\n",
        "\n",
        "## ðŸ“‹ PrÃ©-requisitos\n",
        "\n",
        "- Arquivo `ori_pqal.json` disponÃ­vel no caminho configurado\n",
        "- VariÃ¡veis de ambiente configuradas (veja `.env.example`)\n",
        "- DependÃªncias instaladas: `pip install -r requirements.txt`\n",
        "\n",
        "## ðŸ”„ Ordem de ExecuÃ§Ã£o\n",
        "\n",
        "Execute as cÃ©lulas **sequencialmente** (de cima para baixo) para garantir que todas as dependÃªncias estejam carregadas corretamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 0: IMPORTAÃ‡ÃƒO DE BIBLIOTECAS E CONFIGURAÃ‡Ã•ES\n",
        "# ============================================================================\n",
        "# Esta cÃ©lula importa todas as bibliotecas necessÃ¡rias e configura o ambiente\n",
        "# Execute esta cÃ©lula PRIMEIRO antes de qualquer outra operaÃ§Ã£o\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Adiciona o diretÃ³rio raiz ao path para importar mÃ³dulos\n",
        "root_dir = Path.cwd().parent\n",
        "sys.path.insert(0, str(root_dir))\n",
        "\n",
        "# Importa mÃ³dulos do pipeline RAG\n",
        "from scripts.data_loader import (\n",
        "    load_medical_dataset,\n",
        "    validate_dataset_structure,\n",
        "    get_dataset_stats\n",
        ")\n",
        "from config.settings import Settings, get_settings\n",
        "\n",
        "# Carrega configuraÃ§Ãµes\n",
        "settings = get_settings()\n",
        "\n",
        "# Valida configuraÃ§Ãµes\n",
        "is_valid, errors = settings.validate()\n",
        "if not is_valid:\n",
        "    print(\"âŒ ERROS DE CONFIGURAÃ‡ÃƒO:\")\n",
        "    for error in errors:\n",
        "        print(f\"   - {error}\")\n",
        "    print(\"\\nðŸ’¡ Configure as variÃ¡veis de ambiente no arquivo .env\")\n",
        "    raise ValueError(\"ConfiguraÃ§Ãµes invÃ¡lidas\")\n",
        "else:\n",
        "    print(\"âœ… ConfiguraÃ§Ãµes validadas com sucesso!\")\n",
        "    settings.print_config()\n",
        "\n",
        "print(\"\\nâœ… Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 1: CARREGAMENTO DO DATASET MÃ‰DICO\n",
        "# ============================================================================\n",
        "# Esta etapa carrega o arquivo ori_pqal.json que contÃ©m dados mÃ©dicos\n",
        "# estruturados do PubMedQA (dataset de perguntas e respostas mÃ©dicas\n",
        "# baseadas em evidÃªncias cientÃ­ficas)\n",
        "#\n",
        "# Estrutura esperada do dataset:\n",
        "#   {\n",
        "#     \"article_id\": {\n",
        "#       \"QUESTION\": \"Pergunta mÃ©dica...\",\n",
        "#       \"CONTEXTS\": [\"Contexto 1\", \"Contexto 2\", ...],\n",
        "#       \"LONG_ANSWER\": \"Resposta longa baseada em evidÃªncias...\",\n",
        "#       \"MESHES\": [\"Termo1\", \"Termo2\", ...],\n",
        "#       \"YEAR\": \"2011\",\n",
        "#       \"LABELS\": [\"BACKGROUND\", \"RESULTS\"],\n",
        "#       ...\n",
        "#     },\n",
        "#     ...\n",
        "#   }\n",
        "\n",
        "# ObtÃ©m o caminho do arquivo de dados das configuraÃ§Ãµes\n",
        "data_path = settings.MEDICAL_DATA_PATH\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ“‚ CARREGANDO DATASET MÃ‰DICO\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Caminho do arquivo: {data_path}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Carrega o dataset\n",
        "try:\n",
        "    raw_data = load_medical_dataset(data_path)\n",
        "    print(f\"âœ… Dataset carregado com sucesso!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"âŒ Erro: {e}\")\n",
        "    print(\"\\nðŸ’¡ Dica: Verifique se o caminho estÃ¡ correto no arquivo .env\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro ao carregar dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "print(f\"Total de entradas mÃ©dicas: {len(raw_data)}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 2: VALIDAÃ‡ÃƒO DA ESTRUTURA DO DATASET\n",
        "# ============================================================================\n",
        "# Esta etapa valida se a estrutura do dataset estÃ¡ correta e identifica\n",
        "# possÃ­veis problemas ou inconsistÃªncias nos dados\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ” VALIDANDO ESTRUTURA DO DATASET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Valida estrutura\n",
        "is_valid, warnings = validate_dataset_structure(raw_data)\n",
        "\n",
        "if is_valid:\n",
        "    print(\"âœ… Estrutura do dataset vÃ¡lida!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Avisos encontrados:\")\n",
        "    for warning in warnings:\n",
        "        print(f\"   - {warning}\")\n",
        "\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 3: ESTATÃSTICAS DO DATASET\n",
        "# ============================================================================\n",
        "# Esta etapa calcula e exibe estatÃ­sticas detalhadas sobre o dataset\n",
        "# para entender melhor a distribuiÃ§Ã£o e qualidade dos dados\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ“Š ESTATÃSTICAS DO DATASET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calcula estatÃ­sticas\n",
        "stats = get_dataset_stats(raw_data)\n",
        "\n",
        "print(f\"Total de entradas: {stats['total_entries']}\")\n",
        "print(f\"Entradas com QUESTION: {stats['entries_with_question']} ({stats['entries_with_question']/stats['total_entries']*100:.1f}%)\")\n",
        "print(f\"Entradas com CONTEXTS: {stats['entries_with_contexts']} ({stats['entries_with_contexts']/stats['total_entries']*100:.1f}%)\")\n",
        "print(f\"Entradas com LONG_ANSWER: {stats['entries_with_answer']} ({stats['entries_with_answer']/stats['total_entries']*100:.1f}%)\")\n",
        "print(f\"\\nMÃ©dia de contextos por entrada: {stats['avg_contexts_per_entry']:.2f}\")\n",
        "print(f\"Tamanho mÃ©dio das respostas: {stats['avg_answer_length']:.0f} caracteres\")\n",
        "\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 4: EXPLORAÃ‡ÃƒO DE EXEMPLOS\n",
        "# ============================================================================\n",
        "# Esta etapa exibe exemplos reais de entradas do dataset para entender\n",
        "# melhor a estrutura e o conteÃºdo dos dados\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ“„ EXEMPLOS DE ENTRADAS DO DATASET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Pega algumas chaves de exemplo\n",
        "sample_keys = list(raw_data.keys())[:3]\n",
        "\n",
        "for i, article_id in enumerate(sample_keys, 1):\n",
        "    entry = raw_data[article_id]\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EXEMPLO {i} - Artigo ID: {article_id}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # QUESTION\n",
        "    question = entry.get('QUESTION', 'N/A')\n",
        "    print(f\"\\nðŸ“ QUESTION:\")\n",
        "    print(f\"   {question[:200]}{'...' if len(question) > 200 else ''}\")\n",
        "    \n",
        "    # CONTEXTS\n",
        "    contexts = entry.get('CONTEXTS', [])\n",
        "    print(f\"\\nðŸ“š CONTEXTS ({len(contexts)} contextos):\")\n",
        "    for j, ctx in enumerate(contexts[:2], 1):  # Mostra apenas os 2 primeiros\n",
        "        print(f\"   Contexto {j}: {ctx[:150]}{'...' if len(ctx) > 150 else ''}\")\n",
        "    if len(contexts) > 2:\n",
        "        print(f\"   ... e mais {len(contexts) - 2} contextos\")\n",
        "    \n",
        "    # LONG_ANSWER\n",
        "    answer = entry.get('LONG_ANSWER', 'N/A')\n",
        "    print(f\"\\nðŸ’¬ LONG_ANSWER:\")\n",
        "    print(f\"   {answer[:200]}{'...' if len(answer) > 200 else ''}\")\n",
        "    \n",
        "    # MESHES\n",
        "    meshes = entry.get('MESHES', [])\n",
        "    print(f\"\\nðŸ·ï¸  MESHES ({len(meshes)} termos):\")\n",
        "    if meshes:\n",
        "        print(f\"   {', '.join(meshes[:10])}\")\n",
        "        if len(meshes) > 10:\n",
        "            print(f\"   ... e mais {len(meshes) - 10} termos\")\n",
        "    \n",
        "    # YEAR\n",
        "    year = entry.get('YEAR', 'N/A')\n",
        "    print(f\"\\nðŸ“… YEAR: {year}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"âœ… ExploraÃ§Ã£o concluÃ­da!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… ConclusÃ£o da Etapa 1\n",
        "\n",
        "Neste notebook vocÃª:\n",
        "- âœ… Carregou o dataset mÃ©dico do arquivo `ori_pqal.json`\n",
        "- âœ… Validou a estrutura dos dados\n",
        "- âœ… Analisou estatÃ­sticas do dataset\n",
        "- âœ… Explorou exemplos de entradas\n",
        "\n",
        "## ðŸ“Œ PrÃ³ximos Passos\n",
        "\n",
        "Agora vocÃª estÃ¡ pronto para o prÃ³ximo notebook:\n",
        "- **Notebook 02**: Processamento e limpeza dos dados mÃ©dicos\n",
        "- AplicaÃ§Ã£o de anonimizaÃ§Ã£o\n",
        "- PreparaÃ§Ã£o para embedding e ingestÃ£o\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
